{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633b97aa",
   "metadata": {},
   "source": [
    "# Numerical analysis: TP-1\n",
    "<h4 align=\"right\"> Author: <i> Hicham Janati </i></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c945eaa",
   "metadata": {},
   "source": [
    "#### 1) Integers and floating point representations\n",
    "run the following cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6171e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2 * np.ones(1).astype(int)\n",
    "print(f\"a is equal to {a} and its type is {a.dtype}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60, 68):\n",
    "    print(f\"2 ** {i} = {a ** i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac01966",
   "metadata": {},
   "source": [
    "**Q1.  Can you explain the observed behavior ?  Propose a way to fix this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c939e78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae02a39a",
   "metadata": {},
   "source": [
    "**Q2. Does the problem occur without specifying the dtype `np.ones(1)`? Deduce a real numpy usecase where this might be a problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ac7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "574334e9",
   "metadata": {},
   "source": [
    " In deep learning applications, chosing the \"right\" dtype is a very important tradeoff between speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540a340",
   "metadata": {},
   "source": [
    "#### 2) Imperfect floating point numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8c4ad",
   "metadata": {},
   "source": [
    "Consider the function $f(x) = 2x$ on $[0, 0.5]$ and $f(x) = 2x - 1$ on $]0.5, 1]$ \n",
    "\n",
    "**Q1.** Consider the sequence defined by $x_{n+1} = f(x_n)$ with $x_0 = 0.1$ Compute the first 5 elements of the sequence (manually). What do you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6edb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "703140fd",
   "metadata": {},
   "source": [
    "**Q2.** Complete the function below that returns $x_n$. What do you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 0.1\n",
    "\n",
    "def f(x, n=100):\n",
    "    \n",
    "    return x\n",
    "\n",
    "f(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37811e",
   "metadata": {},
   "source": [
    "`float64` numbers are represented using 64 bits as:\n",
    "$$(-1)^s \\quad 0.m_1..m_{52} \\quad 2^{e_1..e_{11}}$$\n",
    "where $s$ is a sign bit, $m$ is the mantissa (52 bits) and $e$ is the exponent (11 bits)\n",
    "\n",
    "**Q4** Take a moment a contemplate this mystery. Use the `pretty_float_bits` function below to find an explanation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f833b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def float_to_bin(f) -> str:\n",
    "    fmt = \">d\"\n",
    "    bz = struct.pack(fmt, f)\n",
    "    return \"\".join(f\"{b:08b}\" for b in bz)\n",
    "\n",
    "def sign_exponent_fraction(s):\n",
    "    return s[0:1], s[1:12], s[12:64]\n",
    "\n",
    "def pretty_float_bits(f) -> str:\n",
    "    return \" \".join(sign_exponent_fraction(float_to_bin(f)))\n",
    "\n",
    "pretty_float_bits(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_float_bits(0.1 + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc455468",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_float_bits(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88dae4",
   "metadata": {},
   "source": [
    "With floats, the order matters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd92c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "100. - 100. + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb985cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 + 100. - 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e670da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "517bb030",
   "metadata": {},
   "source": [
    "#### 3) Machine precision and cumulative errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeaccf4",
   "metadata": {},
   "source": [
    "Consider the integral $$I_n = \\int_{0}^1 \\frac{x^n}{x + 10}dx$$\n",
    "\n",
    "1. Without computing $I_n$, find its limit.\n",
    "2. Compute $I_0$ and find a recurrence formula between $I_{n+1}$ and $I_n$\n",
    "3. If we were to compute $I_n$ recursively, would that algorithm be stable numerically ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32426ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral(i0, n):\n",
    "    ii = i0\n",
    "    for jj in range(n):\n",
    "\n",
    "    return ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "integral(np.log(11/10), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39632f2",
   "metadata": {},
   "source": [
    "4. Replace 10 in the integral with a constant A > 1. Given a machine precision variable $\\varepsilon$, how can we set the number of iterations $n$ based on a desired cumulative error E ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd09b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c131b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.finfo(float).eps) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb283da",
   "metadata": {},
   "source": [
    "**Independent questions:**\n",
    "\n",
    "**Q5.** Write a piece of code that can find $\\varepsilon$ numerically. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e5f4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117bca24",
   "metadata": {},
   "source": [
    "**Q6.** Given what you know now, how should you test if two numbers or arrays are equal ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1da659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcbaf2de",
   "metadata": {},
   "source": [
    "#### 4) Logsum-exp trick\n",
    "Consider a classification model with 4 classes. We are modeling the probablity of a sample being in class $k$ with: $$p_k = \\frac{ exp(w_k)}{\\sum_{i=1}^{4} exp(w_i)}$$\n",
    "\n",
    "where $w$ are the weights of a neural net.\n",
    "1. Why does this model make sense ? \n",
    "2. Given the example $w = [-20, -1, 0, 1000]$, it is obvious which class this sample should correspond to. Compute the prediction probabilities using the function below for this particular example. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9f6b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w):\n",
    "    p = np.exp(w)\n",
    "    p /= p.sum()\n",
    "    return p\n",
    "\n",
    "w = np.array([10, -1, 40, 2, 1000])\n",
    "predict(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d025fd",
   "metadata": {},
   "source": [
    "3. Even if we assume that $exp(w_k)$ do not overflow, computing the normalizing sum can cause problems if the number of labels is too large. After showing the following statement, propose a method to modify `predict` in order to avoid overflow errors:\n",
    "$$ \\forall c \\in \\mathbb{R} \\qquad log\\left(\\sum_{k=1}^K exp(w_k + c)\\right) =  c + log\\left(\\sum_{k=1}^K exp(w_k)\\right) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(w):\n",
    "\n",
    "    return ll\n",
    "\n",
    "def predict_stable(w):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c93ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_stable(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d8043",
   "metadata": {},
   "source": [
    "4. Generate random weight vectors with `np.random.randn(K)` and test that both functions return the same probabilities. Test it with the scipy `logsumexp`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea35d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}